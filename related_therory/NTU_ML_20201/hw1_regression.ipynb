{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeaYeh/mini-transformer/blob/main/hw1_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "Q3QKhLtbI0av"
      },
      "outputs": [],
      "source": [
        "data_folder = './work/related_therory/NTU_ML_20201/data/ml2021spring-hw1'  # folder to save data\n",
        "\n",
        "train_path = os.path.join(data_folder, 'covid.train.csv')\n",
        "test_path = os.path.join(data_folder, 'covid.test.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# For data preprocess\n",
        "import numpy as np\n",
        "import csv\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# For plotting\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "myseed = 42\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(myseed)\n",
        "torch.manual_seed(myseed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(myseed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Some Utilities**\n",
        "\n",
        "You do not need to modify this part."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_device():\n",
        "    ''' Get device (if GPU is available, use GPU) '''\n",
        "    return 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "def plot_learning_curve(loss_record, title=''):\n",
        "    ''' Plot learning curve of your DNN (train & dev loss) '''\n",
        "    total_steps = len(loss_record['train'])\n",
        "    x_1 = range(total_steps)\n",
        "    x_2 = x_1[::len(loss_record['train']) // len(loss_record['dev'])]\n",
        "    figure(figsize=(6, 4))\n",
        "    plt.plot(x_1, loss_record['train'], c='tab:red', label='train')\n",
        "    plt.plot(x_2, loss_record['dev'], c='tab:cyan', label='dev')\n",
        "    plt.ylim(0.0, 5.)\n",
        "    plt.xlabel('Training steps')\n",
        "    plt.ylabel('MSE loss')\n",
        "    plt.title('Learning curve of {}'.format(title))\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_pred(dv_set, model, device, lim=35., preds=None, targets=None):\n",
        "    ''' Plot prediction of your DNN '''\n",
        "    if preds is None or targets is None:\n",
        "        model.eval()\n",
        "        preds, targets = [], []\n",
        "        for x, y in dv_set:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            with torch.no_grad():\n",
        "                pred = model(x)\n",
        "                preds.append(pred.detach().cpu())\n",
        "                targets.append(y.detach().cpu())\n",
        "        preds = torch.cat(preds, dim=0).numpy()\n",
        "        targets = torch.cat(targets, dim=0).numpy()\n",
        "\n",
        "    figure(figsize=(5, 5))\n",
        "    plt.scatter(targets, preds, c='r', alpha=0.5)\n",
        "    plt.plot([-0.2, lim], [-0.2, lim], c='b')\n",
        "    plt.xlim(-0.2, lim)\n",
        "    plt.ylim(-0.2, lim)\n",
        "    plt.xlabel('ground truth value')\n",
        "    plt.ylabel('predicted value')\n",
        "    plt.title('Ground Truth v.s. Prediction')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "class COVID19Dataset(Dataset):\n",
        "    ''' Dataset for loading and preprocessing the COVID19 dataset '''\n",
        "    def __init__(self,\n",
        "                 path,\n",
        "                 mode='train',\n",
        "                 target_only=False):\n",
        "        self.mode = mode\n",
        "\n",
        "        # Read data into numpy arrays\n",
        "        with open(path, 'r') as fp:\n",
        "            data = list(csv.reader(fp))\n",
        "            data = np.array(data[1:])[:, 1:].astype(float)\n",
        "\n",
        "        if not target_only:\n",
        "            feats = list(range(93))\n",
        "        else:\n",
        "            # TODO: Using 40 states & 2 tested_positive features (indices = 57 & 75)\n",
        "            pass\n",
        "\n",
        "        if mode == 'test':\n",
        "            # Testing data\n",
        "            # data: 893 x 93 (40 states + day 1 (18) + day 2 (18) + day 3 (17))\n",
        "            data = data[:, feats]\n",
        "            self.data = torch.FloatTensor(data)\n",
        "        else:\n",
        "            # Training data (train/dev sets)\n",
        "            # data: 2700 x 94 (40 states + day 1 (18) + day 2 (18) + day 3 (18))\n",
        "            target = data[:, -1]\n",
        "            data = data[:, feats]\n",
        "\n",
        "            # Splitting training data into train 90% & dev sets 10%\n",
        "            if mode == 'train':\n",
        "                indices = [i for i in range(len(data)) if i % 10 != 0]\n",
        "            elif mode == 'dev':\n",
        "                indices = [i for i in range(len(data)) if i % 10 == 0]\n",
        "\n",
        "            # Convert data into PyTorch tensors\n",
        "            self.data = torch.FloatTensor(data[indices])\n",
        "            self.target = torch.FloatTensor(target[indices])\n",
        "\n",
        "        # Normalize features (you may remove this part to see what will happen)\n",
        "        self.data[:, 40:] = \\\n",
        "            (self.data[:, 40:] - self.data[:, 40:].mean(dim=0, keepdim=True)) \\\n",
        "            / self.data[:, 40:].std(dim=0, keepdim=True)\n",
        "\n",
        "        self.dim = self.data.shape[1]\n",
        "\n",
        "        print('Finished reading the {} set of COVID19 Dataset ({} samples found, each dim = {})'\n",
        "              .format(mode, len(self.data), self.dim))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Returns one sample at a time\n",
        "        if self.mode in ['train', 'dev']:\n",
        "            # For training\n",
        "            return self.data[index], self.target[index]\n",
        "        else:\n",
        "            # For testing (no target)\n",
        "            return self.data[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        # Returns the size of the dataset\n",
        "        return len(self.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished reading the train set of COVID19 Dataset (2430 samples found, each dim = 93)\n",
            "Finished reading the test set of COVID19 Dataset (893 samples found, each dim = 93)\n"
          ]
        }
      ],
      "source": [
        "train_dataset = COVID19Dataset(train_path)\n",
        "test_dataset = COVID19Dataset(test_path, mode='test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2430"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(21.1667)"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>83</th>\n",
              "      <th>84</th>\n",
              "      <th>85</th>\n",
              "      <th>86</th>\n",
              "      <th>87</th>\n",
              "      <th>88</th>\n",
              "      <th>89</th>\n",
              "      <th>90</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2430.000000</td>\n",
              "      <td>2430.000000</td>\n",
              "      <td>2430.000000</td>\n",
              "      <td>2430.000000</td>\n",
              "      <td>2430.000000</td>\n",
              "      <td>2430.000000</td>\n",
              "      <td>2430.000000</td>\n",
              "      <td>2430.000000</td>\n",
              "      <td>2430.000000</td>\n",
              "      <td>2430.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>2.430000e+03</td>\n",
              "      <td>2.430000e+03</td>\n",
              "      <td>2.430000e+03</td>\n",
              "      <td>2430.000000</td>\n",
              "      <td>2.430000e+03</td>\n",
              "      <td>2.430000e+03</td>\n",
              "      <td>2.430000e+03</td>\n",
              "      <td>2.430000e+03</td>\n",
              "      <td>2.430000e+03</td>\n",
              "      <td>2.430000e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.024691</td>\n",
              "      <td>0.024691</td>\n",
              "      <td>0.024691</td>\n",
              "      <td>0.025103</td>\n",
              "      <td>0.024691</td>\n",
              "      <td>0.024691</td>\n",
              "      <td>0.025103</td>\n",
              "      <td>0.024691</td>\n",
              "      <td>0.024691</td>\n",
              "      <td>0.025103</td>\n",
              "      <td>...</td>\n",
              "      <td>8.791072e-07</td>\n",
              "      <td>-2.260561e-07</td>\n",
              "      <td>-7.535205e-07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-3.767602e-08</td>\n",
              "      <td>4.521123e-07</td>\n",
              "      <td>-2.825702e-08</td>\n",
              "      <td>-5.525816e-07</td>\n",
              "      <td>-3.516429e-07</td>\n",
              "      <td>3.767602e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.155217</td>\n",
              "      <td>0.155217</td>\n",
              "      <td>0.155217</td>\n",
              "      <td>0.156468</td>\n",
              "      <td>0.155217</td>\n",
              "      <td>0.155217</td>\n",
              "      <td>0.156468</td>\n",
              "      <td>0.155216</td>\n",
              "      <td>0.155216</td>\n",
              "      <td>0.156468</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>9.999998e-01</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>9.999994e-01</td>\n",
              "      <td>1.000001e+00</td>\n",
              "      <td>9.999999e-01</td>\n",
              "      <td>9.999996e-01</td>\n",
              "      <td>1.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.626976e+00</td>\n",
              "      <td>-2.289557e+00</td>\n",
              "      <td>-2.192807e+00</td>\n",
              "      <td>-1.738353</td>\n",
              "      <td>-1.575330e+00</td>\n",
              "      <td>-2.258796e+00</td>\n",
              "      <td>-2.869911e+00</td>\n",
              "      <td>-2.129226e+00</td>\n",
              "      <td>-2.667851e+00</td>\n",
              "      <td>-2.189435e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>-8.507931e-01</td>\n",
              "      <td>-6.006017e-01</td>\n",
              "      <td>-8.222126e-01</td>\n",
              "      <td>-0.801224</td>\n",
              "      <td>-6.379388e-01</td>\n",
              "      <td>-7.308154e-01</td>\n",
              "      <td>-7.071488e-01</td>\n",
              "      <td>-7.040991e-01</td>\n",
              "      <td>-8.155820e-01</td>\n",
              "      <td>-7.681473e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.548349e-02</td>\n",
              "      <td>-6.121446e-02</td>\n",
              "      <td>-7.273870e-03</td>\n",
              "      <td>-0.115566</td>\n",
              "      <td>-1.770150e-01</td>\n",
              "      <td>-1.704070e-01</td>\n",
              "      <td>-6.352893e-02</td>\n",
              "      <td>-1.781109e-01</td>\n",
              "      <td>1.763778e-01</td>\n",
              "      <td>-1.087954e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>8.053433e-01</td>\n",
              "      <td>8.197246e-01</td>\n",
              "      <td>8.161061e-01</td>\n",
              "      <td>0.716363</td>\n",
              "      <td>3.273488e-01</td>\n",
              "      <td>6.389135e-01</td>\n",
              "      <td>7.084531e-01</td>\n",
              "      <td>5.435468e-01</td>\n",
              "      <td>7.858468e-01</td>\n",
              "      <td>6.776648e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>2.330748e+00</td>\n",
              "      <td>2.077374e+00</td>\n",
              "      <td>2.181660e+00</td>\n",
              "      <td>3.037862</td>\n",
              "      <td>5.492065e+00</td>\n",
              "      <td>4.669538e+00</td>\n",
              "      <td>3.460657e+00</td>\n",
              "      <td>3.376009e+00</td>\n",
              "      <td>2.066225e+00</td>\n",
              "      <td>2.650917e+00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows Ã— 93 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                0            1            2            3            4   \\\n",
              "count  2430.000000  2430.000000  2430.000000  2430.000000  2430.000000   \n",
              "mean      0.024691     0.024691     0.024691     0.025103     0.024691   \n",
              "std       0.155217     0.155217     0.155217     0.156468     0.155217   \n",
              "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
              "\n",
              "                5            6            7            8            9   ...  \\\n",
              "count  2430.000000  2430.000000  2430.000000  2430.000000  2430.000000  ...   \n",
              "mean      0.024691     0.025103     0.024691     0.024691     0.025103  ...   \n",
              "std       0.155217     0.156468     0.155216     0.155216     0.156468  ...   \n",
              "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "50%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "75%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "max       1.000000     1.000000     1.000000     1.000000     1.000000  ...   \n",
              "\n",
              "                 83            84            85           86            87  \\\n",
              "count  2.430000e+03  2.430000e+03  2.430000e+03  2430.000000  2.430000e+03   \n",
              "mean   8.791072e-07 -2.260561e-07 -7.535205e-07     0.000000 -3.767602e-08   \n",
              "std    1.000000e+00  1.000000e+00  9.999998e-01     1.000000  1.000000e+00   \n",
              "min   -2.626976e+00 -2.289557e+00 -2.192807e+00    -1.738353 -1.575330e+00   \n",
              "25%   -8.507931e-01 -6.006017e-01 -8.222126e-01    -0.801224 -6.379388e-01   \n",
              "50%   -2.548349e-02 -6.121446e-02 -7.273870e-03    -0.115566 -1.770150e-01   \n",
              "75%    8.053433e-01  8.197246e-01  8.161061e-01     0.716363  3.273488e-01   \n",
              "max    2.330748e+00  2.077374e+00  2.181660e+00     3.037862  5.492065e+00   \n",
              "\n",
              "                 88            89            90            91            92  \n",
              "count  2.430000e+03  2.430000e+03  2.430000e+03  2.430000e+03  2.430000e+03  \n",
              "mean   4.521123e-07 -2.825702e-08 -5.525816e-07 -3.516429e-07  3.767602e-07  \n",
              "std    9.999994e-01  1.000001e+00  9.999999e-01  9.999996e-01  1.000000e+00  \n",
              "min   -2.258796e+00 -2.869911e+00 -2.129226e+00 -2.667851e+00 -2.189435e+00  \n",
              "25%   -7.308154e-01 -7.071488e-01 -7.040991e-01 -8.155820e-01 -7.681473e-01  \n",
              "50%   -1.704070e-01 -6.352893e-02 -1.781109e-01  1.763778e-01 -1.087954e-01  \n",
              "75%    6.389135e-01  7.084531e-01  5.435468e-01  7.858468e-01  6.776648e-01  \n",
              "max    4.669538e+00  3.460657e+00  3.376009e+00  2.066225e+00  2.650917e+00  \n",
              "\n",
              "[8 rows x 93 columns]"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(train_dataset.data.numpy()).describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "def prep_dataloader(path, mode, batch_size, n_jobs=0, target_only=False):\n",
        "    ''' Generates a dataset, then is put into a dataloader. '''\n",
        "    dataset = COVID19Dataset(path, mode=mode, target_only=target_only)  # Construct dataset\n",
        "    dataloader = DataLoader(\n",
        "        dataset, batch_size,\n",
        "        shuffle=(mode == 'train'), drop_last=False,\n",
        "        num_workers=n_jobs, pin_memory=True)                            # Construct dataloader\n",
        "    return dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "class NeuralNet(nn.Module):\n",
        "    ''' A simple fully-connected deep neural network '''\n",
        "    def __init__(self, input_dim):\n",
        "        super(NeuralNet, self).__init__()\n",
        "\n",
        "        # Define your neural network here\n",
        "        # TODO: How to modify this model to achieve better performance?\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "\n",
        "        # Mean squared error loss\n",
        "        self.criterion = nn.MSELoss(reduction='mean')\n",
        "\n",
        "    def forward(self, x):\n",
        "        ''' Given input of size (batch_size x input_dim), compute output of the network '''\n",
        "        return self.net(x).squeeze(1)\n",
        "\n",
        "    def cal_loss(self, pred, target):\n",
        "        ''' Calculate loss '''\n",
        "        # TODO: you may implement L1/L2 regularization here\n",
        "        return self.criterion(pred, target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(tr_set, dv_set, model, config, device):\n",
        "    ''' DNN training '''\n",
        "\n",
        "    n_epochs = config['n_epochs']  # Maximum number of epochs\n",
        "\n",
        "    # Setup optimizer\n",
        "    optimizer = getattr(torch.optim, config['optimizer'])(\n",
        "        model.parameters(), **config['optim_hparas'])\n",
        "\n",
        "    min_mse = 1000.\n",
        "    loss_record = {'train': [], 'dev': []}      # for recording training loss\n",
        "    early_stop_cnt = 0\n",
        "    epoch = 0\n",
        "    while epoch < n_epochs:\n",
        "        model.train()                           # set model to training mode\n",
        "        for x, y in tr_set:                     # iterate through the dataloader\n",
        "            optimizer.zero_grad()               # set gradient to zero\n",
        "            x, y = x.to(device), y.to(device)   # move data to device (cpu/cuda)\n",
        "            pred = model(x)                     # forward pass (compute output)\n",
        "            mse_loss = model.cal_loss(pred, y)  # compute loss\n",
        "            mse_loss.backward()                 # compute gradient (backpropagation)\n",
        "            optimizer.step()                    # update model with optimizer\n",
        "            loss_record['train'].append(mse_loss.detach().cpu().item())\n",
        "\n",
        "        # After each epoch, test your model on the validation (development) set.\n",
        "        dev_mse = dev(dv_set, model, device)\n",
        "        if dev_mse < min_mse:\n",
        "            # Save model if your model improved\n",
        "            min_mse = dev_mse\n",
        "            print('Saving model (epoch = {:4d}, loss = {:.4f})'\n",
        "                .format(epoch + 1, min_mse))\n",
        "            torch.save(model.state_dict(), config['save_path'])  # Save model to specified path\n",
        "            early_stop_cnt = 0\n",
        "        else:\n",
        "            early_stop_cnt += 1\n",
        "\n",
        "        epoch += 1\n",
        "        loss_record['dev'].append(dev_mse)\n",
        "        if early_stop_cnt > config['early_stop']:\n",
        "            # Stop training if your model stops improving for \"config['early_stop']\" epochs.\n",
        "            break\n",
        "\n",
        "    print('Finished training after {} epochs'.format(epoch))\n",
        "    return min_mse, loss_record"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "def dev(dv_set, model, device):\n",
        "    model.eval()                                # set model to evalutation mode\n",
        "    total_loss = 0\n",
        "    for x, y in dv_set:                         # iterate through the dataloader\n",
        "        x, y = x.to(device), y.to(device)       # move data to device (cpu/cuda)\n",
        "        with torch.no_grad():                   # disable gradient calculation\n",
        "            pred = model(x)                     # forward pass (compute output)\n",
        "            mse_loss = model.cal_loss(pred, y)  # compute loss\n",
        "        total_loss += mse_loss.detach().cpu().item() * len(x)  # accumulate loss\n",
        "    total_loss = total_loss / len(dv_set.dataset)              # compute averaged loss\n",
        "\n",
        "    return total_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test(tt_set, model, device):\n",
        "    model.eval()                                # set model to evalutation mode\n",
        "    preds = []\n",
        "    for x in tt_set:                            # iterate through the dataloader\n",
        "        x = x.to(device)                        # move data to device (cpu/cuda)\n",
        "        with torch.no_grad():                   # disable gradient calculation\n",
        "            pred = model(x)                     # forward pass (compute output)\n",
        "            preds.append(pred.detach().cpu())   # collect prediction\n",
        "    preds = torch.cat(preds, dim=0).numpy()     # concatenate all predictions and convert to a numpy array\n",
        "    return preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = get_device()                 # get the current available device ('cpu' or 'cuda')\n",
        "os.makedirs('models', exist_ok=True)  # The trained model will be saved to ./models/\n",
        "target_only = False                   # TODO: Using 40 states & 2 tested_positive features\n",
        "\n",
        "# TODO: How to tune these hyper-parameters to improve your model's performance?\n",
        "config = {\n",
        "    'n_epochs': 3000,                # maximum number of epochs\n",
        "    'batch_size': 270,               # mini-batch size for dataloader\n",
        "    'optimizer': 'SGD',              # optimization algorithm (optimizer in torch.optim)\n",
        "    'optim_hparas': {                # hyper-parameters for the optimizer (depends on which optimizer you are using)\n",
        "        'lr': 0.001,                 # learning rate of SGD\n",
        "        'momentum': 0.9              # momentum for SGD\n",
        "    },\n",
        "    'early_stop': 200,               # early stopping epochs (the number epochs since your model's last improvement)\n",
        "    'save_path': 'models/model.pth'  # your model will be saved here\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished reading the train set of COVID19 Dataset (2430 samples found, each dim = 93)\n",
            "Finished reading the dev set of COVID19 Dataset (270 samples found, each dim = 93)\n",
            "Finished reading the test set of COVID19 Dataset (893 samples found, each dim = 93)\n"
          ]
        }
      ],
      "source": [
        "tr_set = prep_dataloader(train_path, 'train', config['batch_size'], target_only=target_only)\n",
        "dv_set = prep_dataloader(train_path, 'dev', config['batch_size'], target_only=target_only)\n",
        "tt_set = prep_dataloader(test_path, 'test', config['batch_size'], target_only=target_only)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = NeuralNet(tr_set.dataset.dim).to(device)  # Construct model and move to device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNchj2GYtViDwYDMk4hYflv",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
